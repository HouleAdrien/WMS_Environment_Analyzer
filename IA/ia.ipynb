{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_masks(satellite_folder, mask_folder):\n",
    "    satellite_images = []\n",
    "    masks = []\n",
    "    for filename in os.listdir(satellite_folder):\n",
    "        sat_img = Image.open(os.path.join(satellite_folder, filename))\n",
    "        mask_img = Image.open(os.path.join(mask_folder, filename))  # Assurez-vous que les noms correspondent\n",
    "\n",
    "        satellite_images.append(np.array(sat_img))\n",
    "        masks.append(np.array(mask_img))\n",
    "\n",
    "    return np.array(satellite_images), np.array(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_to_label = {\n",
    "    (180, 180, 180): 0,  # Gris - Végétation clairsemée\n",
    "    (0, 100, 0): 1,     # Vert - Couverture arborée\n",
    "    (255, 187, 34): 2,  # Orange - Broussailles\n",
    "    (255, 255, 76): 3,  # Jaune - Prairie\n",
    "    (240, 150, 255): 4, # Rose - Terre cultivée\n",
    "    (250, 0, 0): 5,     # Rouge - Zones urbanisées\n",
    "    (240, 240, 240): 6, # Blanc - Neige et glace\n",
    "    (0, 100, 200): 7,   # Bleu - Plans d'eau permanents\n",
    "    (0, 150, 160): 8,   # Vert-bleu - Marais herbacé\n",
    "    (0, 207, 117): 9,   # Vert mangrove - Mangroves\n",
    "    (250, 230, 160): 10 # Mousse - Lichens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Esa_tile1_resize\\\\ESA_WorldCover_10m_2021_V200_N30W003_Map_TrueMarble.250m.21600x21600.D2.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m path_satellite_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEsa_tile1_Sat\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Chemin vers les images satellites\u001b[39;00m\n\u001b[0;32m      2\u001b[0m path_labelled_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEsa_tile1_resize\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Chemin vers les images labelisées (masques)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_and_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_satellite_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_labelled_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m Y \u001b[38;5;241m=\u001b[39m to_categorical(Y)  \u001b[38;5;66;03m# Convertir les masques en catégories\u001b[39;00m\n\u001b[0;32m      7\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mload_images_and_masks\u001b[1;34m(satellite_folder, mask_folder)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(satellite_folder):\n\u001b[0;32m      5\u001b[0m     sat_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(satellite_folder, filename))\n\u001b[1;32m----> 6\u001b[0m     mask_img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assurez-vous que les noms correspondent\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     satellite_images\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(sat_img))\n\u001b[0;32m      9\u001b[0m     masks\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(mask_img))\n",
      "File \u001b[1;32m~\\.conda\\envs\\mon_env_ia\\lib\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Esa_tile1_resize\\\\ESA_WorldCover_10m_2021_V200_N30W003_Map_TrueMarble.250m.21600x21600.D2.tif'"
     ]
    }
   ],
   "source": [
    "path_satellite_images = 'Esa_tile1_Sat'  # Chemin vers les images satellites\n",
    "path_labelled_images = 'Esa_tile1_resize'  # Chemin vers les images labelisées (masques)\n",
    "\n",
    "X, Y = load_images_and_masks(path_satellite_images, path_labelled_images)\n",
    "Y = to_categorical(Y)  # Convertir les masques en catégories\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unet_model(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Couches descendantes\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "\n",
    "    # Couches ascendantes\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Remplacer par la forme réelle de vos images et le nombre de canaux (par exemple, (1440, 1440, 3) pour des images RGB)\n",
    "model = create_unet_model((1440, 1440, 3), num_classes=11)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=5, validation_data=(X_test, Y_test))\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
