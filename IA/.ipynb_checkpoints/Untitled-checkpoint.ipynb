{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af29e4-55ee-4b34-82f9-b011f015c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "\n",
    "color_to_label = {\n",
    "    (180, 180, 180): 0,  # Gris - Végétation clairsemée\n",
    "    (0, 100, 0): 1,     # Vert - Couverture arborée\n",
    "    (255, 187, 34): 2,  # Orange - Broussailles\n",
    "    (255, 255, 76): 3,  # Jaune - Prairie\n",
    "    (240, 150, 255): 4, # Rose - Terre cultivée\n",
    "    (250, 0, 0): 5,     # Rouge - Zones urbanisées\n",
    "    (240, 240, 240): 6, # Blanc - Neige et glace\n",
    "    (0, 100, 200): 7,   # Bleu - Plans d'eau permanents\n",
    "    (0, 150, 160): 8,   # Vert-bleu - Marais herbacé\n",
    "    (0, 207, 117): 9,   # Vert mangrove - Mangroves\n",
    "    (250, 230, 160): 10, # Mousse - Lichens\n",
    "    (0, 0, 0): 11       # Noir - Sans données\n",
    "}\n",
    "\n",
    "def label_to_class(label_img):\n",
    "    # Convertir en RGB si nécessaire\n",
    "    label_img = label_img.convert('RGB')\n",
    "    label_array = np.array(label_img)\n",
    "    height, width = label_array.shape[:2]\n",
    "    class_map = np.zeros((height, width), dtype=int)\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel = tuple(label_array[y, x])\n",
    "            class_idx = color_to_label.get(pixel, 11)  # Utilisez -1 ou un autre numéro pour les couleurs non mappées\n",
    "            class_map[y, x] = class_idx\n",
    "\n",
    "    return class_map\n",
    "\n",
    "\n",
    "def load_images_and_masks(satellite_folder, mask_folder):\n",
    "    satellite_images = []\n",
    "    masks = []\n",
    "    for filename in os.listdir(satellite_folder):\n",
    "        sat_img = Image.open(os.path.join(satellite_folder, filename))\n",
    "        mask_img = Image.open(os.path.join(mask_folder, filename))  # Assurez-vous que les noms correspondent\n",
    "\n",
    "        satellite_images.append(np.array(sat_img))\n",
    "        masks.append(label_to_class(mask_img))\n",
    "\n",
    "    return np.array(satellite_images), np.array(masks)\n",
    "\n",
    "\n",
    "path_satellite_images = 'TrainData\\Esa_tile2_Sat'  # Chemin vers les images satellites\n",
    "path_labelled_images = 'TrainData\\Esa_tile2_resize'  # Chemin vers les images labelisées (masques)\n",
    "\n",
    "#X, Y = load_images_and_masks(path_satellite_images, path_labelled_images)\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "\n",
    "def EncoderMiniBlock(inputs, n_filters=12, dropout_prob=0.3, max_pooling=True):\n",
    "    conv = Conv2D(n_filters, \n",
    "                  3,  # filter size\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='HeNormal')(inputs)\n",
    "    conv = Conv2D(n_filters, \n",
    "                  3,  # filter size\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='HeNormal')(conv)\n",
    "  \n",
    "    conv = BatchNormalization()(conv, training=False)\n",
    "    if dropout_prob > 0:     \n",
    "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
    "    if max_pooling:\n",
    "        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)    \n",
    "    else:\n",
    "        next_layer = conv\n",
    "    skip_connection = conv    \n",
    "    return next_layer, skip_connection\n",
    "\n",
    "def DecoderMiniBlock(prev_layer_input, skip_layer_input, n_filters=12):\n",
    "    up = Conv2DTranspose(\n",
    "                 n_filters,\n",
    "                 (3,3),\n",
    "                 strides=(2,2),\n",
    "                 padding='same')(prev_layer_input)\n",
    "    merge = concatenate([up, skip_layer_input], axis=3)\n",
    "    conv = Conv2D(n_filters, \n",
    "                 3,  \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='HeNormal')(merge)\n",
    "    conv = Conv2D(n_filters,\n",
    "                 3, \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='HeNormal')(conv)\n",
    "    return conv\n",
    "\n",
    "def create_unet_model(input_shape, num_classes,n_filters=32):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "  # Encoder includes multiple convolutional mini blocks with different maxpooling, dropout and filter parameters\n",
    "    # Observe that the filters are increasing as we go deeper into the network which will increasse the # channels of the image \n",
    "    cblock1 = EncoderMiniBlock(inputs, n_filters,dropout_prob=0, max_pooling=True)\n",
    "    cblock2 = EncoderMiniBlock(cblock1[0],n_filters*2,dropout_prob=0, max_pooling=True)\n",
    "    cblock3 = EncoderMiniBlock(cblock2[0], n_filters*4,dropout_prob=0, max_pooling=True)\n",
    "    cblock4 = EncoderMiniBlock(cblock3[0], n_filters*8,dropout_prob=0.3, max_pooling=True)\n",
    "    cblock5 = EncoderMiniBlock(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False) \n",
    "    \n",
    "    # Decoder includes multiple mini blocks with decreasing number of filters\n",
    "    # Observe the skip connections from the encoder are given as input to the decoder\n",
    "    # Recall the 2nd output of encoder block was skip connection, hence cblockn[1] is used\n",
    "    ublock6 = DecoderMiniBlock(cblock5[0], cblock4[1],  n_filters * 8)\n",
    "    ublock7 = DecoderMiniBlock(ublock6, cblock3[1],  n_filters * 4)\n",
    "    ublock8 = DecoderMiniBlock(ublock7, cblock2[1],  n_filters * 2)\n",
    "    ublock9 = DecoderMiniBlock(ublock8, cblock1[1],  n_filters)\n",
    "\n",
    "    conv9 = Conv2D(n_filters,\n",
    "                 3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "\n",
    "    conv10 = Conv2D(num_classes, 1, padding='same')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "    return model\n",
    "\n",
    "# Remplacer par la forme réelle de vos images et le nombre de canaux (par exemple, (1440, 1440, 3) pour des images RGB)\n",
    "model = create_unet_model((1440, 1440, 3), num_classes=12)\n",
    "model.compile(optimizer='adam', \n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True),  # Assuming softmax activation in the last layer\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load the model from the HDF5 file\n",
    "model_path = 'testmodel.h5'  # Change this to the path of your model file\n",
    "model = load_model(model_path)\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.metrics import SparseCategoricalCrossentropy\n",
    "\n",
    "label_to_color = {v: k for k, v in color_to_label.items()}\n",
    "\n",
    "# Charger et prétraiter l'image\n",
    "def load_and_preprocess_image(image_path, target_size):\n",
    "    image = load_img(image_path, target_size=target_size) # Assurez-vous que target_size correspond à la taille d'entrée du modèle\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0) # Ajouter une dimension pour le batch\n",
    "    return image\n",
    "\n",
    "def prediction_to_image(prediction):\n",
    "    # Prendre l'indice de la classe la plus probable\n",
    "    prediction = np.argmax(prediction, axis=-1)\n",
    "\n",
    "    # Initialiser une image RGB vide\n",
    "    colored_prediction = np.zeros((prediction.shape[0], prediction.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Appliquer la couleur à chaque pixel\n",
    "    for label, color in label_to_color.items():\n",
    "        colored_prediction[prediction == label] = color\n",
    "\n",
    "    return Image.fromarray(colored_prediction)\n",
    "\n",
    "# Faire une prédiction et afficher avec Pillow\n",
    "def predict_and_display(model, image_path, target_size=(1440, 1440)):\n",
    "    image = load_and_preprocess_image(image_path, target_size)\n",
    "    prediction = model.predict(image)[0] # Récupérer la prédiction pour le premier élément du batch\n",
    "\n",
    "    # Convertir la prédiction en image PIL et afficher\n",
    "    original_image = Image.open(image_path)\n",
    "    predicted_image = prediction_to_image(prediction)\n",
    "\n",
    "    original_image.show(title='Image Originale')\n",
    "    predicted_image.show(title='Prédiction du Modèle')\n",
    "\n",
    "def predict_and_save(model, source_folder, destination_folder, target_size=(1440, 1440)):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(source_folder):\n",
    "        # Load and preprocess the image\n",
    "        image_path = os.path.join(source_folder, filename)\n",
    "        image = load_and_preprocess_image(image_path, target_size)\n",
    "\n",
    "        # Make predictions\n",
    "        prediction = model.predict(image)[0]  # Get the prediction for the first element of the batch\n",
    "\n",
    "        # Convert the prediction to an image and save it\n",
    "        predicted_image = prediction_to_image(prediction)\n",
    "        save_path = os.path.join(destination_folder, f\"predicted_{filename}\")\n",
    "        predicted_image.save(save_path)\n",
    "\n",
    "# Example usage\n",
    "source_folder = 'TrainData\\Esa_tile2_Sat'  # Replace with the path to your source folder\n",
    "destination_folder = 'TrainData\\Esa_tile2_res1'  # Replace with the path to your destination folder\n",
    "\n",
    "predict_and_save(model, source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72582daa-879c-4302-9ca0-3491323124af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
